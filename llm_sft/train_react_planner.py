# train_react_planner.py
# ReAct Planner SFT (LoRA, bf16 / no bitsandbytes)

import os
from dataclasses import dataclass
from typing import Dict, Optional, List
from config.paths import REACT_DATA_JSONL, REACT_LORA_OUT
from config.config import BASE_MODEL_NAME

import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
)
from peft import LoraConfig
from trl import SFTTrainer


# -------------------------------------------------------
# 0) ê¸°ë³¸ ì„¤ì •
# -------------------------------------------------------

# í•™ìŠµ ë°ì´í„° íŒŒì¼ (2ë‹¨ê³„ì—ì„œ ë§Œë“  JSONL)
DATA_PATH = REACT_DATA_JSONL.as_posix()

# LoRA ê²°ê³¼ ì €ì¥ ê²½ë¡œ
OUTPUT_DIR = REACT_LORA_OUT.as_posix()


# -------------------------------------------------------
# 1) Dataset ë¡œë“œ
#   - JSONL: {"prompt": "...", "response": "..."} êµ¬ì¡°
# -------------------------------------------------------

def load_react_dataset(path: str):
    """
    react_sft_data.jsonl ì„ datasets í¬ë§·ìœ¼ë¡œ ë¡œë“œ.
    """
    dataset = load_dataset("json", data_files=path)
    # dataset["train"] í•˜ë‚˜ë§Œ ì“°ë©´ ì¶©ë¶„ (train / test ë‚˜ëˆ„ê³  ì‹¶ìœ¼ë©´ split ê°€ëŠ¥)
    return dataset["train"]


# -------------------------------------------------------
# 2) í…ìŠ¤íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜
#    - prompt + response ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹œë‹¤.
#    - ì¶”ë¡  ë•ŒëŠ” "promptë§Œ ë„£ê³  -> ëª¨ë¸ì´ response(3ì¤„)ë¥¼ ì´ì–´ì„œ ìƒì„±"í•˜ê²Œ ì‚¬ìš©.
# -------------------------------------------------------

def formatting_func(batch: Dict[str, List[str]]) -> List[str]:
    """
    batch["prompt"], batch["response"] ë¥¼ ë°›ì•„ì„œ
    "prompt + response" í˜•íƒœì˜ ë‹¨ì¼ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¡œ í•©ì¹œë‹¤.
    """
    outputs = []
    prompts = batch["prompt"]
    responses = batch["response"]

    for p, r in zip(prompts, responses):
        # ì¤‘ê°„ì— êµ¬ë¶„ ì¤„ í•˜ë‚˜ ì •ë„ë§Œ ë„£ê³  ë°”ë¡œ responseë¥¼ ë¶™ì¸ë‹¤.
        text = p.rstrip() + "\n" + r.strip()
        outputs.append(text)

    return outputs


# -------------------------------------------------------
# 3) ëª¨ë¸ / í† í¬ë‚˜ì´ì € ë¡œë“œ (bf16 LoRA, no bitsandbytes)
# -------------------------------------------------------

def load_model_and_tokenizer():
    print(f"[ğŸ”„] Loading base model (bf16, no bitsandbytes): {BASE_MODEL_NAME}")

    # 3-1) í† í¬ë‚˜ì´ì €
    tokenizer = AutoTokenizer.from_pretrained(
        BASE_MODEL_NAME,
        use_fast=False,
    )

    # pad_token ì—†ìœ¼ë©´ eos_tokenìœ¼ë¡œ ë§ì¶°ì£¼ê¸°
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # SFTì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ right padding ì‚¬ìš©
    tokenizer.padding_side = "right"

    # 3-2) ëª¨ë¸ ë¡œë“œ (bfloat16, ì–‘ìí™” ì—†ìŒ)
    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_NAME,
        torch_dtype=torch.bfloat16,   # âœ… bf16
        device_map="auto",            # ì—¬ëŸ¬ GPU ìˆìœ¼ë©´ ìë™ ë¶„ì‚°
    )

    # LoRA í•™ìŠµ ì‹œì—ëŠ” use_cache=False ë¡œ ë‘ëŠ” ê²Œ ì•ˆì •ì 
    if hasattr(model, "config"):
        model.config.use_cache = False

    print("[âœ…] Model & tokenizer loaded (bf16, no quantization)")
    return model, tokenizer


# -------------------------------------------------------
# 4) LoRA ì„¤ì •
# -------------------------------------------------------

def make_lora_config():
    """
    Planner ì „ìš© LoRA ì„¤ì •.
    ë„ˆë¬´ aggressive í•˜ì§€ ì•Šê²Œ ì ë‹¹í•œ r, alpha ì‚¬ìš©.
    """
    lora_config = LoraConfig(
        r=64,
        lora_alpha=16,
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules=[
            "q_proj",
            "k_proj",
            "v_proj",
            "o_proj",
            "gate_proj",
            "up_proj",
            "down_proj",
        ],
    )
    return lora_config


# -------------------------------------------------------
# 5) TrainingArguments ì„¤ì •
# -------------------------------------------------------

def make_training_args(output_dir: str) -> TrainingArguments:
    """
    A100 80GB ê¸°ì¤€, ê°€ë²¼ìš´ SFT ì˜ˆì‹œìš© ì„¤ì •.
    (ì‹¤ì œ ë°ì´í„°ê°€ ëŠ˜ì–´ë‚˜ë©´ epoch/step ì¡°ì • ê°€ëŠ¥)
    """
    args = TrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=1,      # 30B ê¸°ì¤€ ì•ˆì „í•œ ë°°ì¹˜ì‚¬ì´ì¦ˆ
        gradient_accumulation_steps=16,     # effective batch size ~= 16
        num_train_epochs=3,                 # ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì¡°ì •
        learning_rate=2e-4,
        lr_scheduler_type="cosine",
        warmup_ratio=0.03,
        logging_steps=10,
        save_strategy="steps",
        save_steps=100,
        save_total_limit=2,

        # âœ… fp16 ìŠ¤ì¼€ì¼ë§ ë„ê³  bf16ë§Œ ì‚¬ìš©
        fp16=False,
        bf16=True,

        gradient_checkpointing=True,

        # bitsandbytes 8bit ì˜µí‹°ë§ˆì´ì € ëŒ€ì‹ , í‘œì¤€ AdamW ì‚¬ìš©
        optim="adamw_torch",

        report_to=[],
    )
    return args


# -------------------------------------------------------
# 6) main: ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸
# -------------------------------------------------------

def main():
    # 6-1) Dataset ë¡œë“œ
    print("[ğŸ“] Loading dataset...")
    train_dataset = load_react_dataset(DATA_PATH)
    print(f"[ğŸ“] Train samples: {len(train_dataset)}")

    # 6-2) ëª¨ë¸ / í† í¬ë‚˜ì´ì € ë¡œë“œ
    model, tokenizer = load_model_and_tokenizer()

    # 6-3) LoRA ì„¤ì •
    lora_config = make_lora_config()

    # 6-4) TrainingArguments ì„¤ì •
    training_args = make_training_args(OUTPUT_DIR)

    # 6-5) SFTTrainer ìƒì„±
    print("[ğŸš€] Starting SFT training (ReAct Planner)...")

    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=train_dataset,
        peft_config=lora_config,
        formatting_func=formatting_func,   # prompt+responseë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        max_seq_length=1024,               # ReAct í”„ë¡¬í”„íŠ¸+ì‘ë‹µ ê¸¸ì´ ì—¬ìœ  ìˆê²Œ
        args=training_args,
    )

    # 6-6) í•™ìŠµ ì‹œì‘
    trainer.train()

    # 6-7) LoRA ì–´ëŒ‘í„° ì €ì¥
    trainer.save_model()
    print(f"[âœ…] LoRA planner model saved to: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
