import unicodedata
import torch

from config.config import TEMPERATURE, MAX_NEW_TOKENS
from llm.model_loader import load_hf_model

# üîπ ReAct PlannerÏö© Ï†ÑÏó≠ Î™®Îç∏ ÏÑ∏ÌåÖ Ìï®Ïàò Í∞ÄÏ†∏Ïò§Í∏∞
from llm.planner_inference import set_planner_model


# ‚úÖ 1) Î≤†Ïù¥Ïä§ + LoRA Î™®Îç∏ Ìïú Î≤à Î°úÎìú
tokenizer, model = load_hf_model()

# ‚úÖ 2) pad_token ÏÑ§Ï†ï (Í∏∞Ï°¥ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# ‚úÖ 3) ReAct Planner Ï™ΩÏóêÏÑúÎèÑ ÎèôÏùº Î™®Îç∏/ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Ïó∞Í≤∞
#    - Ïù¥Î†áÍ≤å ÌïòÎ©¥ planner_generate()Í∞Ä Ïù¥ Î™®Îç∏ÏùÑ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
set_planner_model(model, tokenizer)


def _clean_text(text: str) -> str:
    text = unicodedata.normalize("NFC", text or "")
    cleaned = []
    for ch in text:
        if ch == "\ufffd":
            continue
        if ch == "\n" or ch.isprintable():
            cleaned.append(ch)
    return "".join(cleaned)


def llm_chat(prompt: str, max_new_tokens: int | None = None) -> str:
    """
    prompt -> reply
    max_new_tokens Î•º Ï£ºÎ©¥ Í∑∏ Í∞í ÏÇ¨Ïö©, ÏïÑÎãàÎ©¥ config Ïùò MAX_NEW_TOKENS ÏÇ¨Ïö©.
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    inputs = tokenizer(
        prompt,
        return_tensors="pt",
        add_special_tokens=True,
    ).to(device)

    new_tokens = max_new_tokens if max_new_tokens is not None else MAX_NEW_TOKENS

    with torch.no_grad():
        output_ids = model.generate(
            **inputs,
            max_new_tokens=new_tokens,
            temperature=TEMPERATURE,
            do_sample=False,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )

    full_text = tokenizer.decode(
        output_ids[0],
        skip_special_tokens=True,
        clean_up_tokenization_spaces=True,
    )

    # prompt Î∂ÄÎ∂Ñ Ï†úÍ±∞
    if full_text.startswith(prompt):
        reply = full_text[len(prompt):].strip()
    else:
        reply = full_text.strip()

    reply = _clean_text(reply)
    return reply
